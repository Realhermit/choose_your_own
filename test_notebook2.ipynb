{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DonorsChoose.org Project Submission",
        "## Introduction",
        "This notebook presents a machine learning solution to predict the approval status of project proposals submitted to DonorsChoose.org. The goal is to automate the approval prediction process, reduce processing time, improve decision-making, enhance user experience, and optimize resource allocation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import pandas as pd",
        "import numpy as np",
        "from datetime import datetime",
        "import matplotlib.pyplot as plt",
        "import seaborn as sns",
        "import nltk",
        "from nltk.corpus import stopwords",
        "from nltk import pos_tag",
        "from nltk.tokenize import word_tokenize",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report",
        "from sklearn.ensemble import RandomForestClassifier",
        "from sklearn.tree import DecisionTreeClassifier",
        "from sklearn.naive_bayes import GaussianNB",
        "import xgboost as xgb",
        "from sklearn.linear_model import LogisticRegression",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler",
        "from sklearn.decomposition import LatentDirichletAllocation",
        "from sklearn.compose import ColumnTransformer",
        "from sklearn.pipeline import Pipeline, FeatureUnion",
        "from sklearn.base import BaseEstimator, TransformerMixin",
        "import shap",
        "from sklearn.utils.class_weight import compute_sample_weight",
        "import plotly.graph_objects as go",
        "from plotly.subplots import make_subplots",
        "import plotly.express as px",
        "import joblib",
        "import os",
        "from sklearn.model_selection import ParameterGrid",
        "from sklearn.metrics import roc_curve, auc",
        "from sklearn.linear_model import SGDClassifier, SGDRegressor",
        "from sklearn.feature_selection import SelectKBest, f_classif",
        "from ipywidgets import interactive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading",
        "Load the dataset and take a preliminary look at the data structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "odf = pd.read_csv('train_data.csv')",
        "odf_r = pd.read_csv('resources.csv')",
        "df = odf.copy()",
        "df_r = odf_r.copy()",
        "df.info()",
        "df_r.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploratory Data Analysis",
        "Perform exploratory data analysis to understand the dataset better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "df['project_essay'] = df[['project_essay_1', 'project_essay_2', 'project_essay_3', 'project_essay_4']].apply(lambda x: ','.join(x.dropna()), axis=1)",
        "df['project_essay_3_4_present'] = [0 if pd.isnull(i) else 1 for i in df['project_essay_3'].values]",
        "fig = make_subplots(rows=3, cols=2, start_cell='bottom-left', specs=[[{}, {}], [{'colspan': 2}, None], [{'colspan': 2}, None]], subplot_titles=('Presence of additional project essays vs Project Approval', 'Project Grade Category vs Project Approval', 'State vs Project approval', 'Teacher Prefix vs Project approval'))",
        "def create_bar_chart(colname, rowpos, colpos):",
        "    d1 = data.groupby(colname)['project_is_approved'].mean().round(3).sort_values(ascending=False).reset_index()",
        "    fig.add_trace(go.Bar(x=d1[colname], y=d1.project_is_approved, text=round(d1.project_is_approved, 3),textposition='auto', name=colname), row=rowpos, col=colpos)\n",
        "\n",
        "create_bar_chart('teacher_prefix', 3, 1)\n",
        "create_bar_chart('school_state', 2, 1)\n",
        "create_bar_chart('project_grade_category', 1, 2)\n",
        "create_bar_chart('project_essay_3_4_present', 1, 1)\n",
        "\n",
        "# Update xaxis properties\n",
        "fig.update_xaxes(title_text='teacher_prefix', row=3, col=1)\n",
        "fig.update_xaxes(title_text='school_state', row=2, col=1)\n",
        "fig.update_xaxes(title_text='project_grade_category', row=1, col=2)\n",
        "fig.update_xaxes(title_text='project_essay_3_4_present', row=1, col=1)\n",
        "fig.update_layout(height=750)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing and Feature Engineering",
        "Prepare the data for modeling by handling missing data, encoding categorical variables, and creating new features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Merge resource data with project data\n",
        "df_r['total_price'] = df_r['quantity'] * df_r['price']\n",
        "df_r_g = df_r.groupby('id')[['quantity', 'total_price']].sum().reset_index()\n",
        "dft = df.merge(df_r_g, on='id', how='left')\n",
        "\n",
        "# Feature Engineering: Split categories, extract date features, and one-hot encode categorical variables\n",
        "dfc = dft.copy()\n",
        "dfc = split_categories(dfc, 'project_subject_categories')\n",
        "dfc = split_categories(dfc, 'project_subject_subcategories')\n",
        "dfc = extract_date_features(dfc, 'project_submitted_datetime')\n",
        "dfc = one_hot_encode_with_prefix(dfc, 'teacher_prefix')\n",
        "dfc = one_hot_encode_with_prefix(dfc, 'school_state')\n",
        "dfc = one_hot_encode_with_prefix(dfc, 'project_grade_category')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training and Hyperparameter Search",
        "Train various machine learning models and perform hyperparameter tuning to optimize model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Split data into features and target\n",
        "target = 'project_is_approved'\n",
        "X = dfc[[i for i in dfc.columns if i != target]].copy()\n",
        "y = dfc[target].copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scale = StandardScaler()\n",
        "X_train = scale.fit_transform(X_train)\n",
        "X_test = scale.transform(X_test)\n",
        "\n",
        "# Define and train models\n",
        "model_log = LogisticRegression(class_weight='balanced')\n",
        "model_tree = DecisionTreeClassifier(class_weight='balanced')\n",
        "model_gauss = GaussianNB()\n",
        "model_sgd = SGDClassifier()\n",
        "model_log.fit(X_train, y_train)\n",
        "model_tree.fit(X_train, y_train)\n",
        "model_gauss.fit(X_train, y_train)\n",
        "model_sgd.fit(X_train, y_train)\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid_log = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'saga']}\n",
        "grid_log = GridSearchCV(model_log, param_grid_log, cv=5, scoring='accuracy')\n",
        "grid_log.fit(X_train, y_train)\n",
        "\n",
        "param_grid_tree = {'max_depth': [10, 20, 30],, 'min_samples_split': [2, 5, 10]}\n",
        "grid_tree = GridSearchCV(model_tree, param_grid_tree, cv=5, scoring='accuracy')\n",
        "grid_tree.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the best models from hyperparameter tuning\n",
        "best_log = grid_log.best_estimator_\n",
        "best_tree = grid_tree.best_estimator_\n",
        "evaluate_model(best_log, X_test, y_test)\n",
        "evaluate_model(best_tree, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation\n",
        "Evaluate the performance of the trained models using various metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "def evaluate_model(model, X_test, y_test):\n",
        " y_pred = model.predict(X_test)\n",
        " accuracy = accuracy_score(y_test, y_pred)\n",
        " precision = precision_score(y_test, y_pred, average='binary')\n",
        " recall = recall_score(y_test, y_pred, average='binary')\n",
        " print(f\"Accuracy: {accuracy:.2f}\")\n",
        " print(f\"Precision: {precision:.2f}\")\n",
        " print(f\"Recall: {recall:.2f}\")\n",
        " print(\"\nClassification Report:\n\", classification_report(y_test, y_pred))\n",
        " cm = confusion_matrix(y_test, y_pred)\n",
        " sns.heatmap(cm, annot=True, fmt='d')\n",
        " plt.show()\n",
        "\n",
        "evaluate_model(model_log, X_test, y_test)\n",
        "evaluate_model(model_tree, X_test, y_test)\n",
        "evaluate_model(model_gauss, X_test, y_test)\n",
        "evaluate_model(model_sgd, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "Summarize the findings and suggest next steps for improving model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The analysis and modeling process revealed several insights into factors that influence project approval. Moving forward, further exploration into feature engineering and advanced modeling techniques could potentially improve the predictive performance. Additionally, deploying the model into a production environment to provide real-time predictions could be beneficial for strategic decision-making."
      ]
    }
  ]
}